# Enable Rewrite Engine
RewriteEngine On

# Force HTTPS
RewriteCond %{HTTPS} !=on
RewriteRule ^ https://%{HTTP_HOST}%{REQUEST_URI} [L,R=301]

# Detect bot-like or scraper User-Agents (broad list)
SetEnvIfNoCase User-Agent "(YandexWebmaster|YandexBot|Chrome-Lighthouse|Google-Site-Verification|VK|TelegramBot|redditbot|bing|yandex|googlebot|bingbot|slurp|duckduckbot|baiduspider|facebookexternalhit|linkedinbot|twitterbot|whatsapp|curl|wget|httpclient|python-requests|PostmanRuntime|metatags\.io|scrapy|headlesschrome|phantomjs|puppeteer|selenium|SkypeUriPreview|libwww-perl/[0-9]+\.[0-9]+|Google-InspectionTool|ExoClickBot)" isBot
SetEnvIfNoCase User-Agent "^$" isBot  # Empty User-Agent (used by some scrapers)

# Route bot traffic to static view
RewriteCond %{ENV:isBot} =1

# Exclude assets from being redirected
RewriteCond %{REQUEST_URI} !^/robots\.txt$
RewriteCond %{REQUEST_URI} !^/sitemap\.xml$
RewriteCond %{REQUEST_URI} !^/favicon\.ico$

# Exclude anything inside /api/public/ from being redirected
RewriteCond %{REQUEST_URI} !^/api/public/

RewriteRule ^(.*)$ {DOMAIN}/api/public/api/static?url=%{REQUEST_URI} [P,L]

# Redirect /sitemap.xml to /api/public/sitemap.xml
RewriteCond %{REQUEST_URI} ^/sitemap\.xml$
RewriteRule ^ /api/public/sitemap.xml [L]

# Serve index.html for non-bot traffic
RewriteCond %{ENV:isBot} !=1
RewriteCond %{REQUEST_FILENAME} !-f
RewriteCond %{REQUEST_FILENAME} !-d
RewriteRule ^ index.html [L]